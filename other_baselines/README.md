## I. Static World

The static world model is built based on the identity hypothesis.

```bash
cd other_baselines/static_world
python ./eval_static_world.py
```
#### Parameters:
* **test_idx_dir**: Path of test indexes, which is generated by the standard OCFNet evaluation process. 
* **test_results_dir**: Path of occupancy prediction results. Here we simply set it to the path of OCFNet forecasting results and use the present occupancy prediction results for evaluation. You can also replace them with [OpenOccupancy](https://github.com/JeffWang987/OpenOccupancy) estimation results.
* **gt_dir**: Path of ground-truth segmentations.

##  II. Voxelization of PCP

Voxelization of point cloud prediction requires the outputs of [PCPNet](https://github.com/Blurryface0814/PCPNet). Here we use nuScenes-Occupancy as ground-truth since predicted points are limited by sparsity.
```bash
cd other_baselines/voxel_pcp
python ./eval_voxel_pcp.py
```
#### Parameters:
* **test_idx_dir**: Path of test indexes, which is generated by the standard OCFNet evaluation process.
* **occ_path**: Path of nuScenes-Occupancy.
* **test_results_dir**: Path of point cloud prediction results. The data is organized as follows:

```bash
Cam4DOcc
├── data/
│   ├── cam4docc/
│   │   ├── pcpnet_results/
│   │   │   ├── point_clouds/
│   │   │   │   ├── past/
│   │   │   │   │   ├── 000000.ply
│   │   │   │   │   ├── 000001.ply
│   │   │   │   │   ├── 000002.ply
│   │   │   │   │   ├── 000003.ply
│   │   │   │   ├── pred/
│   │   │   │   │   ├── 000000.ply
│   │   │   │   │   ├── ...
│   │   │   ├── saved_labels/
│   │   │   │   ├── past/
│   │   │   │   │   ├── 000000.label
│   │   │   │   │   ├── 000001.label
│   │   │   │   │   ├── 000002.label
│   │   │   │   │   ├── 000003.label
│   │   │   │   ├── pred/
│   │   │   │   │   ├── 000000.ply
│   │   │   │   │   ├── ...
```
We will provide our PCPNet predictions soon and please open an issue [here](https://github.com/Blurryface0814/PCPNet) if you have questions about how PCPNet is implemented for points forecasting.

## III. 2D-3D Lifted Prediction

2D-3D lifted prediction requires the outputs of [PowerBEV](https://github.com/EdwardLeeLPZ/PowerBEV). 

```bash
cd other_baselines/lifted_2d
python ./eval_lifted_2d.py
```
#### Parameters:
* **test_idx_dir**: Path of test indexes, which is generated by the standard OCFNet evaluation process.
* **gt_dir**: Path of ground-truth segmentations.
* **hmin**: minimum height for lifting operation.
* **hmax**: maximum height for lifting operation.
* **test_results_dir**: Path of point cloud prediction results. The data is organized as follows:
```bash
Cam4DOcc
├── data/
│   ├── cam4docc/
│   │   ├── powerbev_results/
│   │   │   ├── {scene_token}_{lidar_token}.npz
│   │   │   ├── ...
```
We have provided our [PowerBEV predictions](https://drive.google.com/file/d/1X_N-GwU2ZB65UI9-EYpeQrb2BzS44VVX/view?usp=sharing) and please open an issue [here](https://github.com/EdwardLeeLPZ/PowerBEV) if you have questions about how PowerBEV is implemented for BEV-based instance prediction.

More refinement strategies for the baselines will be released ... Before that, please simply use the scripts here for fast evaluation.

## Publications

If you use our proposed baselines in your work, please cite as:

* Cam4DOcc
```
@inproceedings{ma2024cvpr,
	author = {Junyi Ma and Xieyuanli Chen and Jiawei Huang and Jingyi Xu and Zhen Luo and Jintao Xu and Weihao Gu and Rui Ai and Hesheng Wang},
	title = {{Cam4DOcc: Benchmark for Camera-Only 4D Occupancy Forecasting in Autonomous Driving Applications}},
	booktitle = {Proc.~of the IEEE/CVF Conf.~on Computer Vision and Pattern Recognition (CVPR)},
	year = 2024
}
```

* OpenOccupancy
```
@article{wang2023openoccupancy,
  title={Openoccupancy: A large scale benchmark for surrounding semantic occupancy perception},
  author={Wang, Xiaofeng and Zhu, Zheng and Xu, Wenbo and Zhang, Yunpeng and Wei, Yi and Chi, Xu and Ye, Yun and Du, Dalong and Lu, Jiwen and Wang, Xingang},
  journal={arXiv preprint arXiv:2303.03991},
  year={2023}
}
```

* PCPNet
```
@ARTICLE{10141631,
  author={Luo, Zhen and Ma, Junyi and Zhou, Zijie and Xiong, Guangming},
  journal={IEEE Robotics and Automation Letters}, 
  title={PCPNet: An Efficient and Semantic-Enhanced Transformer Network for Point Cloud Prediction}, 
  year={2023},
  volume={8},
  number={7},
  pages={4267-4274},
  doi={10.1109/LRA.2023.3281937}}
```
* PowerBEV
```
@inproceedings{ijcai2023p120,
  title     = {PowerBEV: A Powerful Yet Lightweight Framework for Instance Prediction in Bird’s-Eye View},
  author    = {Li, Peizheng and Ding, Shuxiao and Chen, Xieyuanli and Hanselmann, Niklas and Cordts, Marius and Gall, Juergen},
  booktitle = {Proceedings of the Thirty-Second International Joint Conference on
               Artificial Intelligence, {IJCAI-23}},
  pages     = {1080--1088},
  year      = {2023},
  month     = {8},
  doi       = {10.24963/ijcai.2023/120},
}
```







